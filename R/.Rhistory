#'   group_id = groups
#' )
lib_stabilized_metacells_by_group <- function(count_matrix, meta_cells_num=1000,  group_id, similarity_matrix=NULL, seed=123){
# Input validation
if (!is.matrix(count_matrix)) {
stop("count_matrix must be a matrix")
}
if (length(group_id) != ncol(count_matrix)) {
stop("group_id length must match number of cells in count_matrix")
}
if (meta_cells_num <= 0) {
stop("meta_cells_num must be a positive integer")
}
if (!is.null(similarity_matrix) &&
(nrow(similarity_matrix) != ncol(count_matrix) ||
ncol(similarity_matrix) != ncol(count_matrix))) {
stop("similarity_matrix dimensions must match count_matrix columns")
}
cells_seq_dep <- apply(count_matrix, 2, sum)
seq_dep_sum <- sum(cells_seq_dep)
group_seq_dep <- list()
count_matrices <- list()
group_id <- as.character(group_id)
similarity_matrices <- list()
unique_groups <- unique(group_id)
# Split data by groups
for (id in unique_groups){
sub_data <- count_matrix[, group_id==id]
count_matrices[[as.character(id)]] <- sub_data
group_seq_dep[[as.character(id)]] <- sum(apply(sub_data, 2, sum))
if (!is.null(similarity_matrix)){
sub_similarity_matrix <- similarity_matrix[,group_id==id]
similarity_matrices[[as.character(id)]] <- sub_similarity_matrix
}
else{
similarity_matrices[[as.character(id)]] <- NULL
}
}
# Calculate meta-cells per group proportional to sequencing depth
sub_cells_num <- round((unlist(group_seq_dep)/seq_dep_sum) * meta_cells_num)
# Process each group separately
sub_output_list <-list()
for (i in names(sub_cells_num)){
message("Processing group: ", i" (", ncol(count_matrices[[i]]), " cells)")
#'
#' @examples
#' # Example usage:
#' data(sample_counts) # genes x cells matrix
#' groups <- rep(c("A","B"), each=100) # 200 cells
#' metacells <- lib_stabilized_metacells_by_group(
#'   count_matrix = sample_counts,
#'   meta_cells_num = 20,
#'   group_id = groups
#' )
lib_stabilized_metacells_by_group <- function(count_matrix, meta_cells_num=1000,  group_id, similarity_matrix=NULL, seed=123){
# Input validation
if (!is.matrix(count_matrix)) {
stop("count_matrix must be a matrix")
}
if (length(group_id) != ncol(count_matrix)) {
stop("group_id length must match number of cells in count_matrix")
}
if (meta_cells_num <= 0) {
stop("meta_cells_num must be a positive integer")
}
if (!is.null(similarity_matrix) &&
(nrow(similarity_matrix) != ncol(count_matrix) ||
ncol(similarity_matrix) != ncol(count_matrix))) {
stop("similarity_matrix dimensions must match count_matrix columns")
}
cells_seq_dep <- apply(count_matrix, 2, sum)
seq_dep_sum <- sum(cells_seq_dep)
group_seq_dep <- list()
count_matrices <- list()
group_id <- as.character(group_id)
similarity_matrices <- list()
unique_groups <- unique(group_id)
# Split data by groups
for (id in unique_groups){
sub_data <- count_matrix[, group_id==id]
count_matrices[[as.character(id)]] <- sub_data
group_seq_dep[[as.character(id)]] <- sum(apply(sub_data, 2, sum))
if (!is.null(similarity_matrix)){
sub_similarity_matrix <- similarity_matrix[,group_id==id]
similarity_matrices[[as.character(id)]] <- sub_similarity_matrix
}
else{
similarity_matrices[[as.character(id)]] <- NULL
}
}
# Calculate meta-cells per group proportional to sequencing depth
sub_cells_num <- round((unlist(group_seq_dep)/seq_dep_sum) * meta_cells_num)
# Process each group separately
sub_output_list <-list()
for (i in names(sub_cells_num)){
message("Processing group: ", i," (", ncol(count_matrices[[i]]), " cells)")
if (sub_cells_num[i]==0){sub_cells_num_num <- 1} else{sub_cells_num_num <- sub_cells_num[i]}
# sub_output <- lib_stabilized_metacells(count_matrices[[i]], similarity_matrix[[i]],meta_cells_num=sub_cells_num[i], seed=seed)
# colnames(sub_output) <- paste(i, colnames(sub_output), sep="_")
# sub_output_list[[i]] <-sub_output
tryCatch({
sub_output <- lib_stabilized_metacells(
count_matrices[[i]],
similarity_matrices[[i]],
meta_cells_num = sub_cells_num[i],
seed = seed
)
colnames(sub_output) <- paste(i, colnames(sub_output), sep="_")
sub_output_list[[i]] <- sub_output
}, error = function(e) {
warning("Failed to process group ", i, ": ", e$message)
})
}
# Combine all group results
output <- do.call(cbind, sub_output_list[!sapply(sub_output_list, is.null)])
if (is.null(output)) {
stop("No valid meta-cells were created from any group")
}
message("Successfully created ", ncol(output), " meta-cells across ",
length(unique_groups), " groups")
return(output)
}
metacells <- lib_stabilized_metacells_by_group(
count_matrix = sample_counts,
meta_cells_num = 20,
group_id = groups
)
metacells <- lib_stabilized_metacells_by_group(
count_matrix = as.matrix(sample_counts),
meta_cells_num = 20,
group_id = groups
)
seq_depth <- c(1000,1501,800,1200,2000,900,100,700)
similarity <- matrix(runif(64), nrow=8)
seq_dep <- seq_depth
similarity_matrix <- similarity
meta_cells_num=3
total_sets <- seq_along(seq_dep)
total_sets
target_lib_size <- sum(seq_dep)/meta_cells_num
target_lib_size
meta_cells <- list()
iteration=0
iteration = iteration + 1
# Start with cell having smallest remaining library size
start_node <- which.min(seq_dep)
start_node
seq_dep[start_node]
last_depth <- 0
current_depth <- seq_dep[start_node]
current_meta_cell <- c(start_node)
calculate_affinity_probabilities(total_sets, current_meta_cell, similarity_matrix)
current_sets=current_meta_cell
current_sets
total_sets
# Initialize result vector with 0 for current metacell members
affinities <- setNames(rep(0, length(total_sets)), total_sets)
affinities
names(affinities)
# Identify target cells (not in current metacell)
target_cells <- setdiff(total_sets, current_sets)
target_cells
target_cells
numeric(1)
test <- function(x){}
test <- function(x){
c(x,x+1)
numeric(1)}
test(1)
test(1)
test <- function(x){
c(x,x+1)
numeric(1)}
test(1)
test <- function(x){
c(x,x+1)
numeric(2)}
test(1)
vapply(target_cells, function(cell) {
mean(similarity_matrix[cell, current_sets, drop = FALSE])
}, numeric(1))
?vapply
target_cells
affinities
# Normalize to get probabilities
affinities[target_cells] <- mean_similarities / sum(mean_similarities)
# Calculate mean similarities for target cells
mean_similarities <- vapply(target_cells, function(cell) {
mean(similarity_matrix[cell, current_sets, drop = FALSE])
}, numeric(2))
# Normalize to get probabilities
affinities[target_cells] <- mean_similarities / sum(mean_similarities)
# Calculate mean similarities for target cells
mean_similarities <- vapply(target_cells, function(cell) {
mean(similarity_matrix[cell, current_sets, drop = FALSE])
}, numeric(1))
# Normalize to get probabilities
affinities[target_cells] <- mean_similarities / sum(mean_similarities)
affinities
#' all_cells <- paste0("Cell", 1:100)
#' current_metacell <- c("Cell1", "Cell5", "Cell10")
#' sim_mat <- matrix(runif(10000), nrow = 100, dimnames = list(all_cells, all_cells))
#'
#' # Calculate affinity probabilities
#' aff_probs <- calculate_affinity_probabilities(
#'   total_sets = all_cells,
#'   current_sets = current_metacell,
#'   similarity_matrix = sim_mat
#' )
calculate_affinity_probabilities <- function(total_sets, current_sets, similarity_matrix) {
# Input validation
if (!all(current_sets %in% total_sets)) {
stop("All current_sets must be present in total_sets")
}
if (!identical(rownames(similarity_matrix), colnames(similarity_matrix))) {
stop("Similarity matrix must be symmetric (identical row and column names)")
}
if (any(is.na(similarity_matrix))) {
stop("Similarity matrix contains NA values")
}
# Initialize result vector with 0 for current metacell members
affinities <- setNames(rep(0, length(total_sets)), total_sets)
# Identify target cells (not in current metacell)
target_cells <- setdiff(total_sets, current_sets)
if (length(target_cells) == 0) {
return(affinities)  # All cells are in current metacell
}
# Calculate mean similarities for target cells
mean_similarities <- vapply(target_cells, function(cell) {
mean(similarity_matrix[cell, current_sets, drop = FALSE])
}, numeric(1))
# Normalize to get probabilities
affinities[target_cells] <- mean_similarities / sum(mean_similarities)
return(affinities)
}
current_sets
#' all_cells <- paste0("Cell", 1:100)
#' current_metacell <- c("Cell1", "Cell5", "Cell10")
#' sim_mat <- matrix(runif(10000), nrow = 100, dimnames = list(all_cells, all_cells))
#'
#' # Calculate affinity probabilities
#' aff_probs <- calculate_affinity_probabilities(
#'   total_sets = all_cells,
#'   current_sets = current_metacell,
#'   similarity_matrix = sim_mat
#' )
calculate_affinity_probabilities <- function(total_sets, current_sets, similarity_matrix) {
# Input validation
if (!all(current_sets %in% total_sets)) {
stop("All current_sets must be present in total_sets")
}
if (!identical(rownames(similarity_matrix), colnames(similarity_matrix))) {
stop("Similarity matrix must be symmetric (identical row and column names)")
}
if (any(is.na(similarity_matrix))) {
stop("Similarity matrix contains NA values")
}
# Initialize result vector with 0 for current metacell members
affinities <- setNames(rep(0, length(total_sets)), total_sets)
# Identify target cells (not in current metacell)
target_cells <- setdiff(total_sets, current_sets)
if (length(target_cells) == 0) {
return(affinities)  # All cells are in current metacell
}
# Calculate mean similarities for target cells
mean_similarities <- vapply(target_cells, function(cell) {
mean(similarity_matrix[cell, current_sets, drop = FALSE])
}, numeric(1))
# Normalize to get probabilities
affinities[target_cells] <- mean_similarities / sum(mean_similarities)
return(affinities)
}
next_probs <- calculate_affinity_probabilities(total_sets, current_meta_cell, similarity_matrix)
next_probs
sample.int(length(next_probs), size=1, prob=next_probs)
# Sample next cell weighted by affinity probabilities
#set.seed(seed)
new_node <- sample.int(length(next_probs), size=1, prob=next_probs)
last_depth <- current_depth
current_depth <- current_depth + seq_dep[new_node]
current_meta_cell <- c(current_meta_cell, new_node)
current_depth
abs(current_depth - target_lib_size)
abs(last_depth - target_lib_size)
current_meta_cell
#'   \item Values are aggregated counts of constituent cells
#' }
#' @export
#'
#'@importFrom WGCNA `cor`
#'
#' @examples
#' # Example usage:
#' data(sample_counts) # A genes x cells count matrix
#' metacells <- lib_stabilized_metacells(as.matrix(sample_counts), meta_cells_num = 5)
lib_stabilized_metacells <- function(count_matrix, similarity_matrix=NULL, meta_cells_num=1000, seed=123){
# Input validation
if (!is.matrix(count_matrix)) {
stop("count_matrix must be a matrix")
}
if (any(count_matrix < 0)) {
stop("count_matrix contains negative values")
}
if (meta_cells_num <= 0 || meta_cells_num > ncol(count_matrix)) {
stop("meta_cells_num must be between 1 and number of cells")
}
# Set random seed if provided
if (!is.numeric(seed)) {
stop("seed must be an number")
}
# Create similarity matrix if not provided
if (is.null(similarity_matrix)){
message("Computing cell-cell similaritys by pearson correlation...")
similarity_matrix <- process_similarity_matrix(cor(log2(count_matrix+0.00001)))
}
if (ncol(count_matrix) != nrow(similarity_matrix)) {
stop("dimension of similarity_matrix must match cell numbers in count_matrix")
}
# Calculate transition probabilities
message("Calculating cell affinities...")
similarity_matrix <- process_similarity_matrix(similarity_matrix)
seq_dep <- apply(count_matrix, 2, sum)
mean_cells <- ncol(count_matrix)/meta_cells_num
#Filter outlier cells with extremely high library sizes
filtered <- seq_dep < (median(seq_dep) * mean_cells * 1.5)
if (sum(filtered) < ncol(count_matrix)) {
message("Filtered out ", ncol(count_matrix) - sum(filtered), " outlier cells")
count_matrix <- count_matrix[, filtered, drop = FALSE]
similarity_matrix <- similarity_matrix[filtered, filtered, drop = FALSE]
seq_dep <- seq_dep[filtered]
}
#Construct meta-cells
message("Building meta-cells...")
meta_index <- meta_cells_index(seq_dep, similarity_matrix, meta_cells_num=meta_cells_num, seed=seed)
# Create final meta-cell matrix
meta_cells <- create_meta_cell_matrix(count_matrix, meta_index)
rownames(meta_cells) <- rownames(count_matrix)
message(paste("Successfully created", ncol(meta_cells), "meta-cells"))
return(meta_cells)
}
#'
#' @examples
#' # Example usage:
#' data(sample_counts) # genes x cells matrix
#' groups <- rep(c("A","B"), each=100) # 200 cells
#' metacells <- lib_stabilized_metacells_by_group(
#'   count_matrix = sample_counts,
#'   meta_cells_num = 20,
#'   group_id = groups
#' )
lib_stabilized_metacells_by_group <- function(count_matrix, meta_cells_num=1000,  group_id, similarity_matrix=NULL, seed=123){
# Input validation
if (!is.matrix(count_matrix)) {
stop("count_matrix must be a matrix")
}
if (length(group_id) != ncol(count_matrix)) {
stop("group_id length must match number of cells in count_matrix")
}
if (meta_cells_num <= 0) {
stop("meta_cells_num must be a positive integer")
}
if (!is.null(similarity_matrix) &&
(nrow(similarity_matrix) != ncol(count_matrix) ||
ncol(similarity_matrix) != ncol(count_matrix))) {
stop("similarity_matrix dimensions must match count_matrix columns")
}
cells_seq_dep <- apply(count_matrix, 2, sum)
seq_dep_sum <- sum(cells_seq_dep)
group_seq_dep <- list()
count_matrices <- list()
group_id <- as.character(group_id)
similarity_matrices <- list()
unique_groups <- unique(group_id)
# Split data by groups
for (id in unique_groups){
sub_data <- count_matrix[, group_id==id]
count_matrices[[as.character(id)]] <- sub_data
group_seq_dep[[as.character(id)]] <- sum(apply(sub_data, 2, sum))
if (!is.null(similarity_matrix)){
sub_similarity_matrix <- similarity_matrix[,group_id==id]
similarity_matrices[[as.character(id)]] <- sub_similarity_matrix
}
else{
similarity_matrices[[as.character(id)]] <- NULL
}
}
# Calculate meta-cells per group proportional to sequencing depth
sub_cells_num <- round((unlist(group_seq_dep)/seq_dep_sum) * meta_cells_num)
# Process each group separately
sub_output_list <-list()
for (i in names(sub_cells_num)){
message("Processing group: ", i," (", ncol(count_matrices[[i]]), " cells)")
if (sub_cells_num[i]==0){sub_cells_num[i] <- 1}
# sub_output <- lib_stabilized_metacells(count_matrices[[i]], similarity_matrix[[i]],meta_cells_num=sub_cells_num[i], seed=seed)
# colnames(sub_output) <- paste(i, colnames(sub_output), sep="_")
# sub_output_list[[i]] <-sub_output
tryCatch({
sub_output <- lib_stabilized_metacells(
count_matrices[[i]],
similarity_matrices[[i]],
meta_cells_num = sub_cells_num[i],
seed = seed
)
colnames(sub_output) <- paste(i, colnames(sub_output), sep="_")
sub_output_list[[i]] <- sub_output
}, error = function(e) {
warning("Failed to process group ", i, ": ", e$message)
})
}
# Combine all group results
output <- do.call(cbind, sub_output_list[!sapply(sub_output_list, is.null)])
if (is.null(output)) {
stop("No valid meta-cells were created from any group")
}
message("Successfully created ", ncol(output), " meta-cells across ",
length(unique_groups), " groups")
return(output)
}
data(sample_counts)
library(lsmetacell)
data(sample_counts)
#'
#' @examples
#' # Example usage:
#' data(sample_counts) # genes x cells matrix
#' groups <- rep(c("A","B"), each=100) # 200 cells
#' metacells <- lib_stabilized_metacells_by_group(
#'   count_matrix = sample_counts,
#'   meta_cells_num = 20,
#'   group_id = groups
#' )
lib_stabilized_metacells_by_group <- function(count_matrix, meta_cells_num=1000,  group_id, similarity_matrix=NULL, seed=123){
# Input validation
if (!is.matrix(count_matrix)) {
stop("count_matrix must be a matrix")
}
if (length(group_id) != ncol(count_matrix)) {
stop("group_id length must match number of cells in count_matrix")
}
if (meta_cells_num <= 0) {
stop("meta_cells_num must be a positive integer")
}
if (!is.null(similarity_matrix) &&
(nrow(similarity_matrix) != ncol(count_matrix) ||
ncol(similarity_matrix) != ncol(count_matrix))) {
stop("similarity_matrix dimensions must match count_matrix columns")
}
cells_seq_dep <- apply(count_matrix, 2, sum)
seq_dep_sum <- sum(cells_seq_dep)
group_seq_dep <- list()
count_matrices <- list()
group_id <- as.character(group_id)
similarity_matrices <- list()
unique_groups <- unique(group_id)
# Split data by groups
for (id in unique_groups){
sub_data <- count_matrix[, group_id==id]
count_matrices[[as.character(id)]] <- sub_data
group_seq_dep[[as.character(id)]] <- sum(apply(sub_data, 2, sum))
if (!is.null(similarity_matrix)){
sub_similarity_matrix <- similarity_matrix[,group_id==id]
similarity_matrices[[as.character(id)]] <- sub_similarity_matrix
}
else{
similarity_matrices[[as.character(id)]] <- NULL
}
}
# Calculate meta-cells per group proportional to sequencing depth
sub_cells_num <- round((unlist(group_seq_dep)/seq_dep_sum) * meta_cells_num)
# Process each group separately
sub_output_list <-list()
for (i in names(sub_cells_num)){
message("Processing group: ", i," (", ncol(count_matrices[[i]]), " cells)")
if (sub_cells_num[i]==0){sub_cells_num[i] <- 1}
# sub_output <- lib_stabilized_metacells(count_matrices[[i]], similarity_matrix[[i]],meta_cells_num=sub_cells_num[i], seed=seed)
# colnames(sub_output) <- paste(i, colnames(sub_output), sep="_")
# sub_output_list[[i]] <-sub_output
tryCatch({
sub_output <- lib_stabilized_metacells(
count_matrices[[i]],
similarity_matrices[[i]],
meta_cells_num = sub_cells_num[i],
seed = seed
)
colnames(sub_output) <- paste(i, colnames(sub_output), sep="_")
sub_output_list[[i]] <- sub_output
}, error = function(e) {
warning("Failed to process group ", i, ": ", e$message)
})
}
# Combine all group results
output <- do.call(cbind, sub_output_list[!sapply(sub_output_list, is.null)])
if (is.null(output)) {
stop("No valid meta-cells were created from any group")
}
message("Successfully created ", ncol(output), " meta-cells across ",
length(unique_groups), " groups")
return(output)
}
groups <- rep(c("A","B"), each=100)
metacells <- lib_stabilized_metacells_by_group(
count_matrix = sample_counts,
meta_cells_num = 20,
group_id = groups
)
metacells <- lib_stabilized_metacells_by_group(
count_matrix = as.matrix(sample_counts),
meta_cells_num = 20,
group_id = groups
)
metacells
library(lsmetacell)
